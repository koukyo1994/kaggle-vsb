{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "sample_size = 800000\n",
    "n_dim = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c9c1f46b7da78a6b5ae494bea4d41e97a8e20943"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n",
    "        score = matthews_corrcoef(y_true, y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {\"threshold\": best_threshold, \"mcc\": best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "582995257d518e20d09363b85256b4028fc95423"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, n_attention, n_middle, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.n_middle = n_middle\n",
    "        self.n_attention = n_attention\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        self.lin1 = nn.Linear(feature_dim, n_middle)\n",
    "        self.lin2 = nn.Linear(n_middle, n_attention)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = self.lin1(x)\n",
    "\n",
    "        eij = torch.tanh(eij)\n",
    "        \n",
    "        eij = self.lin2(eij)\n",
    "\n",
    "        a = torch.exp(eij).reshape(-1, self.n_attention, step_dim)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "        a = a / torch.sum(a, 2, keepdim=True) + 1e-10\n",
    "        \n",
    "        weighted_input = torch.bmm(a, x)\n",
    "        \n",
    "        return weighted_input, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a714b52d1324878037ab8af9e5b17fdc8c8c6973"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8dd0c7ad56a0f19e48494a290697c024b5053325"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id  target\n",
       "id_measurement phase                   \n",
       "0              0              0       0\n",
       "               1              1       0\n",
       "               2              2       0\n",
       "1              0              3       1\n",
       "               1              4       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../../script/input/metadata_train.csv\")\n",
    "df_train = df_train.set_index([\"id_measurement\", \"phase\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal_id    0\n",
       "target       0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      signal_id\n",
       "id_measurement phase           \n",
       "0              0              0\n",
       "               1              1\n",
       "               2              2\n",
       "1              0              3\n",
       "               1              4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_partial = df_train[[\"signal_id\"]]\n",
    "df_partial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1a8177dfd960a3fe00bb0a81c5ea97b2239c4c22"
   },
   "outputs": [],
   "source": [
    "max_num = 127\n",
    "min_num = -128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d293e6b9780d0f0c29ac783c2a51e310898b3c09"
   },
   "outputs": [],
   "source": [
    "def min_max_transf(ts, min_data, max_data, range_needed=(-1,1)):\n",
    "    if min_data < 0:\n",
    "        ts_std = (ts + abs(min_data)) / (max_data + abs(min_data))\n",
    "    else:\n",
    "        ts_std = (ts - min_data) / (max_data - min_data)\n",
    "    if range_needed[0] < 0:    \n",
    "        return ts_std * (range_needed[1] + abs(range_needed[0])) + range_needed[0]\n",
    "    else:\n",
    "        return ts_std * (range_needed[1] - range_needed[0]) + range_needed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e01338bed32a99459f373e086e5dad9e655051ba"
   },
   "outputs": [],
   "source": [
    "def transform_ts(ts, n_dim=160, min_max=(-1,1)):\n",
    "    # convert data into -1 to 1\n",
    "    ts_std = min_max_transf(ts, min_data=min_num, max_data=max_num)\n",
    "    # bucket or chunk size, 5000 in this case (800000 / 160)\n",
    "    bucket_size = int(sample_size / n_dim)\n",
    "    # new_ts will be the container of the new data\n",
    "    new_ts = []\n",
    "    # this for iteract any chunk/bucket until reach the whole sample_size (800000)\n",
    "    for i in range(0, sample_size, bucket_size):\n",
    "        # cut each bucket to ts_range\n",
    "        ts_range = ts_std[i:i + bucket_size]\n",
    "        # calculate each feature\n",
    "        mean = ts_range.mean()\n",
    "        std = ts_range.std() # standard deviation\n",
    "        std_top = mean + std # I have to test it more, but is is like a band\n",
    "        std_bot = mean - std\n",
    "        # I think that the percentiles are very important, it is like a distribuiton analysis from eath chunk\n",
    "        percentil_calc = np.percentile(ts_range, [0, 1, 25, 50, 75, 99, 100]) \n",
    "        max_range = percentil_calc[-1] - percentil_calc[0] # this is the amplitude of the chunk\n",
    "        relative_percentile = percentil_calc - mean # maybe it could heap to understand the asymmetry\n",
    "        # now, we just add all the features to new_ts and convert it to np.array\n",
    "        new_ts.append(np.concatenate([np.asarray([mean, std, std_top, std_bot, max_range]),percentil_calc, relative_percentile]))\n",
    "    return np.asarray(new_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7262fccaa9b2a94610f3d35622370c46e1a67466"
   },
   "outputs": [],
   "source": [
    "def prep_data(start, end):\n",
    "    # load a piece of data from file\n",
    "    praq_train = pq.read_pandas('../input/train.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    X = []\n",
    "    y = []\n",
    "    # using tdqm to evaluate processing time\n",
    "    # takes each index from df_train and iteract it from start to end\n",
    "    # it is divided by 3 because for each id_measurement there are 3 id_signal, and the start/end parameters are id_signal\n",
    "    bucket_size = int(sample_size / n_dim)\n",
    "    idx = np.array([i for i in range(n_dim) for _ in range(bucket_size)])\n",
    "    praq_train[\"dummy\"] = idx\n",
    "    for id_measurement in tqdm(df_train.index.levels[0].unique()[int(start/3):int(end/3)]):\n",
    "        X_signal = []\n",
    "        # for each phase of the signal\n",
    "        for phase in [0,1,2]:\n",
    "            # extract from df_train both signal_id and target to compose the new data sets\n",
    "            signal_id, target = df_train.loc[id_measurement].loc[phase]\n",
    "            # but just append the target one time, to not triplicate it\n",
    "            if phase == 0:\n",
    "                y.append(target)\n",
    "            # extract and transform data into sets of features\n",
    "            trns = transform_ts(praq_train[str(signal_id)], n_dim=n_dim)\n",
    "            X_signal.append(trns)\n",
    "        # concatenate all the 3 phases in one matrix\n",
    "        X_signal = np.concatenate(X_signal, axis=1)\n",
    "        # add the data to X\n",
    "        X.append(X_signal)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "32e71bf4b7e647810d7911d663a05301dd433f9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1452/1452 [07:40<00:00,  3.12it/s]\n",
      "100%|██████████| 1452/1452 [07:33<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "def load_all():\n",
    "    total_size = len(df_train)\n",
    "    for ini, end in [(0, int(total_size/2)), (int(total_size/2), total_size)]:\n",
    "        X_temp, y_temp = prep_data(ini, end)\n",
    "        X.append(X_temp)\n",
    "        y.append(y_temp)\n",
    "load_all()\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d0319da50e002c53f5bf227d0e45be43b241fddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 160, 57) (2904,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "np.save(\"X.npy\", X)\n",
    "np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "357972109b8d75bae92d58b218fb71dae6f272e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad1ab7975948fa1e75cff1231499940649d811b8"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "768213d384d1d4e2758357fca2bc401bbbfd2940"
   },
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, hidden_size, linear_size, input_shape, n_attention):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.maxlen = input_shape[1]\n",
    "        self.input_dim = input_shape[2]\n",
    "        self.n_attention = n_attention\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            self.input_dim, \n",
    "            hidden_size, \n",
    "            bidirectional=True,\n",
    "            batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            hidden_size * 2,\n",
    "            int(hidden_size / 2),\n",
    "            bidirectional=True,\n",
    "            batch_first=True)\n",
    "        self.attn = Attention(int(hidden_size / 2) * 2, self.maxlen, n_attention, n_attention)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.lin1 = nn.Linear(int(hidden_size / 2) * 2 * n_attention, linear_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(linear_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_lstm1, _ = self.lstm1(x)\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        attn, a = self.attn(h_lstm2)\n",
    "        attn = attn.reshape(\n",
    "            -1, int(self.hidden_size / 2) * 2 * self.n_attention)\n",
    "        #drop =self.drop(attn)\n",
    "        lin = self.relu(self.lin1(attn))\n",
    "        out = self.lin2(lin)\n",
    "        return out, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "a5a339006b7a0c382df95671186c513cb113ebc9"
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "180eeebb1caac02eec1dc8b7ebc1a801f10b40d3"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, filename, anneal=True, epochs=50, seed=1029):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    if anneal:\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    valid = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "    \n",
    "    seed_torch(seed)\n",
    "    train_batch_size = 128\n",
    "    val_batch_size = 512\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=train_batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=val_batch_size, shuffle=False)\n",
    "    \n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction=\"mean\").cuda()\n",
    "    best_score = -np.inf\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        for (x_batch, y_batch) in tqdm(train_loader, disable=True):\n",
    "            y_pred, a = model(x_batch)\n",
    "            \n",
    "            B = y_pred.size(0)\n",
    "            AAT = torch.bmm(a, a.transpose(1, 2))\n",
    "            I = torch.eye(model.n_attention).unsqueeze(0).repeat(B, 1, 1).cuda()\n",
    "            penalization_term = torch.norm(AAT - I) / B\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch) + 0 * penalization_term\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            \n",
    "        model.eval()\n",
    "\n",
    "        valid_preds = np.zeros((X_val.size(0)))\n",
    "        avg_val_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            y_pred, _ = model(x_batch)\n",
    "            y_pred = y_pred.detach()\n",
    "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "            valid_preds[i * val_batch_size:(i + 1) * val_batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "            \n",
    "        search_result = threshold_search(y_val.cpu().numpy(), valid_preds)\n",
    "        val_mcc, val_threshold = search_result[\"mcc\"], search_result[\"threshold\"]\n",
    "        elapsed_time = time.time() - t0\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} loss={avg_loss:.4f} val_loss={avg_val_loss:.4f} val_mcc={val_mcc:.4f} best_t={val_threshold:.2f} time={elapsed_time:.2f}s\")\n",
    "        if anneal:\n",
    "            scheduler.step()\n",
    "            \n",
    "        if val_mcc > best_score:\n",
    "            torch.save(model.state_dict(), filename)\n",
    "            print(f\"Save Model on epoch {epoch + 1}\")\n",
    "            best_score = val_mcc\n",
    "            \n",
    "    avg_val_loss = 0.\n",
    "    valid_preds = np.zeros(X_val.size(0))\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred, _ = model(x_batch)\n",
    "        y_pred = y_pred.detach()\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        valid_preds[i * val_batch_size:(i + 1) * val_batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "    print(\"Validation loss: \", avg_val_loss)\n",
    "    return valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "343b039372674c314bf6b2f299fea682ecd70571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 loss=0.2602 val_loss=0.1995 val_mcc=0.2562 best_t=0.65 time=3.32s\n",
      "Save Model on epoch 1\n",
      "Epoch 2/50 loss=0.2090 val_loss=0.1813 val_mcc=0.3542 best_t=0.09 time=3.21s\n",
      "Save Model on epoch 2\n",
      "Epoch 3/50 loss=0.1833 val_loss=0.2863 val_mcc=0.6639 best_t=0.53 time=3.20s\n",
      "Save Model on epoch 3\n",
      "Epoch 4/50 loss=0.1740 val_loss=0.1267 val_mcc=0.6573 best_t=0.05 time=3.21s\n",
      "Epoch 5/50 loss=0.1300 val_loss=0.1134 val_mcc=0.7389 best_t=0.08 time=3.22s\n",
      "Save Model on epoch 5\n",
      "Epoch 6/50 loss=0.1331 val_loss=0.1012 val_mcc=0.7335 best_t=0.32 time=3.22s\n",
      "Epoch 7/50 loss=0.1179 val_loss=0.1185 val_mcc=0.7081 best_t=0.49 time=3.21s\n",
      "Epoch 8/50 loss=0.1210 val_loss=0.0851 val_mcc=0.7630 best_t=0.09 time=3.22s\n",
      "Save Model on epoch 8\n",
      "Epoch 9/50 loss=0.1318 val_loss=0.0806 val_mcc=0.7655 best_t=0.24 time=3.25s\n",
      "Save Model on epoch 9\n",
      "Epoch 10/50 loss=0.1120 val_loss=0.1595 val_mcc=0.7655 best_t=0.66 time=3.24s\n",
      "Epoch 11/50 loss=0.1296 val_loss=0.0903 val_mcc=0.7760 best_t=0.09 time=3.24s\n",
      "Save Model on epoch 11\n",
      "Epoch 12/50 loss=0.1346 val_loss=0.1067 val_mcc=0.7751 best_t=0.59 time=3.26s\n",
      "Epoch 13/50 loss=0.1327 val_loss=0.0995 val_mcc=0.7584 best_t=0.38 time=3.24s\n",
      "Epoch 14/50 loss=0.1080 val_loss=0.0900 val_mcc=0.7751 best_t=0.51 time=3.25s\n",
      "Epoch 15/50 loss=0.1181 val_loss=0.0752 val_mcc=0.8101 best_t=0.41 time=3.26s\n",
      "Save Model on epoch 15\n",
      "Epoch 16/50 loss=0.1062 val_loss=0.0650 val_mcc=0.7983 best_t=0.19 time=3.30s\n",
      "Epoch 17/50 loss=0.1076 val_loss=0.0831 val_mcc=0.7876 best_t=0.47 time=3.29s\n",
      "Epoch 18/50 loss=0.1266 val_loss=0.0848 val_mcc=0.7967 best_t=0.54 time=3.28s\n",
      "Epoch 19/50 loss=0.1142 val_loss=0.1036 val_mcc=0.7876 best_t=0.57 time=3.31s\n",
      "Epoch 20/50 loss=0.0999 val_loss=0.0683 val_mcc=0.8101 best_t=0.35 time=3.28s\n",
      "Epoch 21/50 loss=0.1019 val_loss=0.0626 val_mcc=0.7927 best_t=0.35 time=3.26s\n",
      "Epoch 22/50 loss=0.1013 val_loss=0.1138 val_mcc=0.7572 best_t=0.69 time=3.26s\n",
      "Epoch 23/50 loss=0.1089 val_loss=0.0702 val_mcc=0.7983 best_t=0.18 time=3.31s\n",
      "Epoch 24/50 loss=0.1075 val_loss=0.0707 val_mcc=0.7927 best_t=0.49 time=3.29s\n",
      "Epoch 25/50 loss=0.0973 val_loss=0.0696 val_mcc=0.8101 best_t=0.21 time=3.28s\n",
      "Epoch 26/50 loss=0.1045 val_loss=0.0788 val_mcc=0.8101 best_t=0.47 time=3.30s\n",
      "Epoch 27/50 loss=0.1009 val_loss=0.0573 val_mcc=0.8223 best_t=0.31 time=3.28s\n",
      "Save Model on epoch 27\n",
      "Epoch 28/50 loss=0.1008 val_loss=0.0637 val_mcc=0.8101 best_t=0.38 time=3.27s\n",
      "Epoch 29/50 loss=0.1066 val_loss=0.0631 val_mcc=0.8101 best_t=0.30 time=3.29s\n",
      "Epoch 30/50 loss=0.1085 val_loss=0.0691 val_mcc=0.7829 best_t=0.36 time=3.31s\n",
      "Epoch 31/50 loss=0.1061 val_loss=0.0779 val_mcc=0.8042 best_t=0.10 time=3.29s\n",
      "Epoch 32/50 loss=0.1115 val_loss=0.0878 val_mcc=0.8142 best_t=0.62 time=3.28s\n",
      "Epoch 33/50 loss=0.1237 val_loss=0.0786 val_mcc=0.7751 best_t=0.36 time=3.29s\n",
      "Epoch 34/50 loss=0.0994 val_loss=0.0593 val_mcc=0.8101 best_t=0.29 time=3.29s\n",
      "Epoch 35/50 loss=0.0930 val_loss=0.0727 val_mcc=0.7751 best_t=0.18 time=3.28s\n",
      "Epoch 36/50 loss=0.0918 val_loss=0.0602 val_mcc=0.7876 best_t=0.26 time=3.27s\n",
      "Epoch 37/50 loss=0.0918 val_loss=0.0764 val_mcc=0.7983 best_t=0.38 time=3.30s\n",
      "Epoch 38/50 loss=0.1006 val_loss=0.0644 val_mcc=0.7478 best_t=0.38 time=3.29s\n",
      "Epoch 39/50 loss=0.0805 val_loss=0.0765 val_mcc=0.7478 best_t=0.24 time=3.28s\n",
      "Epoch 40/50 loss=0.0728 val_loss=0.0829 val_mcc=0.7478 best_t=0.12 time=3.31s\n",
      "Epoch 41/50 loss=0.0762 val_loss=0.0841 val_mcc=0.7103 best_t=0.16 time=3.28s\n",
      "Epoch 42/50 loss=0.0795 val_loss=0.0729 val_mcc=0.7829 best_t=0.55 time=3.26s\n",
      "Epoch 43/50 loss=0.0613 val_loss=0.0782 val_mcc=0.6755 best_t=0.61 time=3.27s\n",
      "Epoch 44/50 loss=0.0646 val_loss=0.1079 val_mcc=0.6569 best_t=0.32 time=3.29s\n",
      "Epoch 45/50 loss=0.0642 val_loss=0.0816 val_mcc=0.6974 best_t=0.08 time=3.28s\n",
      "Epoch 46/50 loss=0.0522 val_loss=0.0930 val_mcc=0.6659 best_t=0.37 time=3.29s\n",
      "Epoch 47/50 loss=0.0391 val_loss=0.1140 val_mcc=0.7195 best_t=0.80 time=3.31s\n",
      "Epoch 48/50 loss=0.0328 val_loss=0.1298 val_mcc=0.6753 best_t=0.92 time=3.27s\n",
      "Epoch 49/50 loss=0.0328 val_loss=0.1209 val_mcc=0.6650 best_t=0.09 time=3.28s\n",
      "Epoch 50/50 loss=0.0407 val_loss=0.1093 val_mcc=0.6729 best_t=0.35 time=3.24s\n",
      "Validation loss:  0.05729246325790882\n",
      "Fold 2\n",
      "Epoch 1/50 loss=0.2894 val_loss=0.2249 val_mcc=0.2459 best_t=0.05 time=3.26s\n",
      "Save Model on epoch 1\n",
      "Epoch 2/50 loss=0.2069 val_loss=0.2181 val_mcc=0.2824 best_t=0.07 time=3.28s\n",
      "Save Model on epoch 2\n",
      "Epoch 3/50 loss=0.1989 val_loss=0.2003 val_mcc=0.4359 best_t=0.04 time=3.27s\n",
      "Save Model on epoch 3\n",
      "Epoch 4/50 loss=0.1857 val_loss=0.1875 val_mcc=0.4483 best_t=0.19 time=3.30s\n",
      "Save Model on epoch 4\n",
      "Epoch 5/50 loss=0.1540 val_loss=0.1375 val_mcc=0.6931 best_t=0.56 time=3.29s\n",
      "Save Model on epoch 5\n",
      "Epoch 6/50 loss=0.1209 val_loss=0.1172 val_mcc=0.7097 best_t=0.27 time=3.26s\n",
      "Save Model on epoch 6\n",
      "Epoch 7/50 loss=0.1176 val_loss=0.1434 val_mcc=0.7299 best_t=0.22 time=3.28s\n",
      "Save Model on epoch 7\n",
      "Epoch 8/50 loss=0.1198 val_loss=0.1186 val_mcc=0.7376 best_t=0.29 time=3.28s\n",
      "Save Model on epoch 8\n",
      "Epoch 9/50 loss=0.1336 val_loss=0.1238 val_mcc=0.7182 best_t=0.25 time=3.31s\n",
      "Epoch 10/50 loss=0.1342 val_loss=0.1665 val_mcc=0.7299 best_t=0.61 time=3.26s\n",
      "Epoch 11/50 loss=0.1291 val_loss=0.1238 val_mcc=0.7299 best_t=0.20 time=3.30s\n",
      "Epoch 12/50 loss=0.1039 val_loss=0.1152 val_mcc=0.7376 best_t=0.60 time=3.29s\n",
      "Epoch 13/50 loss=0.1092 val_loss=0.1129 val_mcc=0.7547 best_t=0.49 time=3.25s\n",
      "Save Model on epoch 13\n",
      "Epoch 14/50 loss=0.1095 val_loss=0.1132 val_mcc=0.7277 best_t=0.61 time=3.27s\n",
      "Epoch 15/50 loss=0.1035 val_loss=0.1137 val_mcc=0.7376 best_t=0.42 time=3.28s\n",
      "Epoch 16/50 loss=0.1063 val_loss=0.1124 val_mcc=0.7376 best_t=0.40 time=3.29s\n",
      "Epoch 17/50 loss=0.1046 val_loss=0.1111 val_mcc=0.7516 best_t=0.51 time=3.30s\n",
      "Epoch 18/50 loss=0.1067 val_loss=0.1137 val_mcc=0.7731 best_t=0.66 time=3.30s\n",
      "Save Model on epoch 18\n",
      "Epoch 19/50 loss=0.0993 val_loss=0.1127 val_mcc=0.7376 best_t=0.37 time=3.29s\n",
      "Epoch 20/50 loss=0.0998 val_loss=0.1114 val_mcc=0.7516 best_t=0.58 time=3.25s\n",
      "Epoch 21/50 loss=0.1067 val_loss=0.1123 val_mcc=0.7422 best_t=0.57 time=3.28s\n",
      "Epoch 22/50 loss=0.1012 val_loss=0.1213 val_mcc=0.7547 best_t=0.58 time=3.28s\n",
      "Epoch 23/50 loss=0.1013 val_loss=0.1176 val_mcc=0.7466 best_t=0.68 time=3.29s\n",
      "Epoch 24/50 loss=0.0983 val_loss=0.1109 val_mcc=0.7547 best_t=0.66 time=3.30s\n",
      "Epoch 25/50 loss=0.0988 val_loss=0.1139 val_mcc=0.7967 best_t=0.57 time=3.31s\n",
      "Save Model on epoch 25\n",
      "Epoch 26/50 loss=0.0974 val_loss=0.1174 val_mcc=0.7001 best_t=0.59 time=3.29s\n",
      "Epoch 27/50 loss=0.0954 val_loss=0.1117 val_mcc=0.7466 best_t=0.64 time=3.26s\n",
      "Epoch 28/50 loss=0.0952 val_loss=0.1087 val_mcc=0.7571 best_t=0.50 time=3.29s\n",
      "Epoch 29/50 loss=0.1005 val_loss=0.1178 val_mcc=0.7466 best_t=0.63 time=3.29s\n",
      "Epoch 30/50 loss=0.1025 val_loss=0.1111 val_mcc=0.7751 best_t=0.55 time=3.29s\n",
      "Epoch 31/50 loss=0.0991 val_loss=0.1156 val_mcc=0.7376 best_t=0.42 time=3.27s\n",
      "Epoch 32/50 loss=0.0909 val_loss=0.1191 val_mcc=0.7277 best_t=0.50 time=3.31s\n",
      "Epoch 33/50 loss=0.0893 val_loss=0.1122 val_mcc=0.7547 best_t=0.60 time=3.30s\n",
      "Epoch 34/50 loss=0.1189 val_loss=0.1135 val_mcc=0.7649 best_t=0.61 time=3.26s\n",
      "Epoch 35/50 loss=0.1062 val_loss=0.1161 val_mcc=0.7466 best_t=0.67 time=3.28s\n",
      "Epoch 36/50 loss=0.0941 val_loss=0.1140 val_mcc=0.7547 best_t=0.66 time=3.29s\n",
      "Epoch 37/50 loss=0.0900 val_loss=0.1210 val_mcc=0.7167 best_t=0.70 time=3.29s\n",
      "Epoch 38/50 loss=0.0938 val_loss=0.1196 val_mcc=0.7299 best_t=0.52 time=3.30s\n",
      "Epoch 39/50 loss=0.0809 val_loss=0.1235 val_mcc=0.7466 best_t=0.74 time=3.30s\n",
      "Epoch 40/50 loss=0.0893 val_loss=0.1202 val_mcc=0.7516 best_t=0.57 time=3.29s\n",
      "Epoch 41/50 loss=0.0806 val_loss=0.1304 val_mcc=0.7277 best_t=0.40 time=3.21s\n",
      "Epoch 42/50 loss=0.0755 val_loss=0.1337 val_mcc=0.7516 best_t=0.53 time=3.24s\n",
      "Epoch 43/50 loss=0.0750 val_loss=0.1465 val_mcc=0.7233 best_t=0.80 time=3.27s\n",
      "Epoch 44/50 loss=0.0661 val_loss=0.1370 val_mcc=0.7203 best_t=0.68 time=3.30s\n",
      "Epoch 45/50 loss=0.0593 val_loss=0.2095 val_mcc=0.7001 best_t=0.13 time=3.28s\n",
      "Epoch 46/50 loss=0.0618 val_loss=0.1592 val_mcc=0.6550 best_t=0.44 time=3.30s\n",
      "Epoch 47/50 loss=0.0526 val_loss=0.1819 val_mcc=0.6175 best_t=0.31 time=3.30s\n",
      "Epoch 48/50 loss=0.0496 val_loss=0.1917 val_mcc=0.6051 best_t=0.14 time=3.27s\n",
      "Epoch 49/50 loss=0.0412 val_loss=0.2446 val_mcc=0.6118 best_t=0.09 time=3.29s\n",
      "Epoch 50/50 loss=0.0390 val_loss=0.2342 val_mcc=0.6165 best_t=0.23 time=3.28s\n",
      "Validation loss:  0.11391598731279373\n",
      "Fold 3\n",
      "Epoch 1/50 loss=0.2730 val_loss=0.1965 val_mcc=0.3494 best_t=0.16 time=3.23s\n",
      "Save Model on epoch 1\n",
      "Epoch 2/50 loss=0.2156 val_loss=0.1913 val_mcc=0.3727 best_t=0.08 time=3.27s\n",
      "Save Model on epoch 2\n",
      "Epoch 3/50 loss=0.1884 val_loss=0.1457 val_mcc=0.4759 best_t=0.14 time=3.25s\n",
      "Save Model on epoch 3\n",
      "Epoch 4/50 loss=0.2534 val_loss=0.1597 val_mcc=0.5816 best_t=0.06 time=3.28s\n",
      "Save Model on epoch 4\n",
      "Epoch 5/50 loss=0.1363 val_loss=0.1184 val_mcc=0.6054 best_t=0.17 time=3.27s\n",
      "Save Model on epoch 5\n",
      "Epoch 6/50 loss=0.1216 val_loss=0.1167 val_mcc=0.6413 best_t=0.28 time=3.29s\n",
      "Save Model on epoch 6\n",
      "Epoch 7/50 loss=0.1100 val_loss=0.1670 val_mcc=0.6230 best_t=0.03 time=3.28s\n",
      "Epoch 8/50 loss=0.1186 val_loss=0.1307 val_mcc=0.6413 best_t=0.09 time=3.26s\n",
      "Epoch 9/50 loss=0.1087 val_loss=0.1427 val_mcc=0.6447 best_t=0.04 time=3.28s\n",
      "Save Model on epoch 9\n",
      "Epoch 10/50 loss=0.1058 val_loss=0.1149 val_mcc=0.6376 best_t=0.23 time=3.28s\n",
      "Epoch 11/50 loss=0.1057 val_loss=0.1425 val_mcc=0.6267 best_t=0.05 time=3.28s\n",
      "Epoch 12/50 loss=0.1250 val_loss=0.1255 val_mcc=0.6176 best_t=0.23 time=3.28s\n",
      "Epoch 13/50 loss=0.1054 val_loss=0.1170 val_mcc=0.6519 best_t=0.14 time=3.28s\n",
      "Save Model on epoch 13\n",
      "Epoch 14/50 loss=0.1003 val_loss=0.1158 val_mcc=0.6376 best_t=0.19 time=3.29s\n",
      "Epoch 15/50 loss=0.1004 val_loss=0.1159 val_mcc=0.6519 best_t=0.19 time=3.25s\n",
      "Epoch 16/50 loss=0.1037 val_loss=0.1183 val_mcc=0.6447 best_t=0.30 time=3.29s\n",
      "Epoch 17/50 loss=0.0939 val_loss=0.1116 val_mcc=0.6447 best_t=0.19 time=3.25s\n",
      "Epoch 18/50 loss=0.0939 val_loss=0.1127 val_mcc=0.6447 best_t=0.19 time=3.27s\n",
      "Epoch 19/50 loss=0.0930 val_loss=0.1232 val_mcc=0.6376 best_t=0.06 time=3.28s\n",
      "Epoch 20/50 loss=0.0989 val_loss=0.1372 val_mcc=0.5384 best_t=0.53 time=3.28s\n",
      "Epoch 21/50 loss=0.1091 val_loss=0.1557 val_mcc=0.6447 best_t=0.02 time=3.30s\n",
      "Epoch 22/50 loss=0.1071 val_loss=0.1162 val_mcc=0.6519 best_t=0.12 time=3.26s\n",
      "Epoch 23/50 loss=0.0921 val_loss=0.1328 val_mcc=0.6447 best_t=0.04 time=3.28s\n",
      "Epoch 24/50 loss=0.0962 val_loss=0.1207 val_mcc=0.6339 best_t=0.06 time=3.26s\n",
      "Epoch 25/50 loss=0.0911 val_loss=0.1191 val_mcc=0.6466 best_t=0.43 time=3.29s\n",
      "Epoch 26/50 loss=0.0956 val_loss=0.1116 val_mcc=0.6447 best_t=0.23 time=3.26s\n",
      "Epoch 27/50 loss=0.0869 val_loss=0.1091 val_mcc=0.6447 best_t=0.16 time=3.28s\n",
      "Epoch 28/50 loss=0.0850 val_loss=0.1094 val_mcc=0.6447 best_t=0.23 time=3.27s\n",
      "Epoch 29/50 loss=0.0962 val_loss=0.1059 val_mcc=0.6447 best_t=0.13 time=3.26s\n",
      "Epoch 30/50 loss=0.0975 val_loss=0.1184 val_mcc=0.6385 best_t=0.39 time=3.27s\n",
      "Epoch 31/50 loss=0.0865 val_loss=0.1119 val_mcc=0.6569 best_t=0.39 time=3.27s\n",
      "Save Model on epoch 31\n",
      "Epoch 32/50 loss=0.0869 val_loss=0.1090 val_mcc=0.6447 best_t=0.13 time=3.30s\n",
      "Epoch 33/50 loss=0.1021 val_loss=0.1063 val_mcc=0.6447 best_t=0.16 time=3.27s\n",
      "Epoch 34/50 loss=0.0896 val_loss=0.1114 val_mcc=0.6447 best_t=0.27 time=3.28s\n",
      "Epoch 35/50 loss=0.0901 val_loss=0.1071 val_mcc=0.6234 best_t=0.05 time=3.28s\n",
      "Epoch 36/50 loss=0.0886 val_loss=0.1155 val_mcc=0.6376 best_t=0.05 time=3.26s\n",
      "Epoch 37/50 loss=0.0863 val_loss=0.1080 val_mcc=0.6447 best_t=0.12 time=3.27s\n",
      "Epoch 38/50 loss=0.0916 val_loss=0.1152 val_mcc=0.6376 best_t=0.38 time=3.25s\n",
      "Epoch 39/50 loss=0.0947 val_loss=0.1067 val_mcc=0.6376 best_t=0.12 time=3.27s\n",
      "Epoch 40/50 loss=0.0918 val_loss=0.1106 val_mcc=0.6376 best_t=0.09 time=3.27s\n",
      "Epoch 41/50 loss=0.0898 val_loss=0.1194 val_mcc=0.6250 best_t=0.32 time=3.28s\n",
      "Epoch 42/50 loss=0.1031 val_loss=0.1358 val_mcc=0.6450 best_t=0.16 time=3.30s\n",
      "Epoch 43/50 loss=0.0906 val_loss=0.1046 val_mcc=0.6447 best_t=0.14 time=3.24s\n",
      "Epoch 44/50 loss=0.0914 val_loss=0.1050 val_mcc=0.6447 best_t=0.20 time=3.26s\n",
      "Epoch 45/50 loss=0.0916 val_loss=0.1052 val_mcc=0.6447 best_t=0.21 time=3.27s\n",
      "Epoch 46/50 loss=0.0855 val_loss=0.1091 val_mcc=0.6624 best_t=0.09 time=3.28s\n",
      "Save Model on epoch 46\n",
      "Epoch 47/50 loss=0.0820 val_loss=0.1067 val_mcc=0.6485 best_t=0.10 time=3.28s\n",
      "Epoch 48/50 loss=0.0826 val_loss=0.1190 val_mcc=0.6376 best_t=0.05 time=3.28s\n",
      "Epoch 49/50 loss=0.0947 val_loss=0.1070 val_mcc=0.6554 best_t=0.24 time=3.29s\n",
      "Epoch 50/50 loss=0.0915 val_loss=0.1075 val_mcc=0.6308 best_t=0.19 time=3.26s\n",
      "Validation loss:  0.10910416394472122\n",
      "Fold 4\n",
      "Epoch 1/50 loss=0.2772 val_loss=0.2033 val_mcc=0.3363 best_t=0.13 time=3.26s\n",
      "Save Model on epoch 1\n",
      "Epoch 2/50 loss=0.2097 val_loss=0.1952 val_mcc=0.3363 best_t=0.41 time=3.27s\n",
      "Epoch 3/50 loss=0.2008 val_loss=0.2172 val_mcc=0.5182 best_t=0.49 time=3.28s\n",
      "Save Model on epoch 3\n",
      "Epoch 4/50 loss=0.2099 val_loss=0.1736 val_mcc=0.4053 best_t=0.10 time=3.27s\n",
      "Epoch 5/50 loss=0.1625 val_loss=0.1422 val_mcc=0.5809 best_t=0.17 time=3.28s\n",
      "Save Model on epoch 5\n",
      "Epoch 6/50 loss=0.1223 val_loss=0.1295 val_mcc=0.5981 best_t=0.39 time=3.29s\n",
      "Save Model on epoch 6\n",
      "Epoch 7/50 loss=0.1275 val_loss=0.1307 val_mcc=0.6301 best_t=0.10 time=3.27s\n",
      "Save Model on epoch 7\n",
      "Epoch 8/50 loss=0.1165 val_loss=0.2049 val_mcc=0.6223 best_t=0.01 time=3.26s\n",
      "Epoch 9/50 loss=0.1303 val_loss=0.1214 val_mcc=0.6445 best_t=0.26 time=3.25s\n",
      "Save Model on epoch 9\n",
      "Epoch 10/50 loss=0.1089 val_loss=0.1141 val_mcc=0.6759 best_t=0.22 time=3.27s\n",
      "Save Model on epoch 10\n",
      "Epoch 11/50 loss=0.1013 val_loss=0.1108 val_mcc=0.6759 best_t=0.17 time=3.29s\n",
      "Epoch 12/50 loss=0.1021 val_loss=0.1103 val_mcc=0.6860 best_t=0.11 time=3.29s\n",
      "Save Model on epoch 12\n",
      "Epoch 13/50 loss=0.1219 val_loss=0.1055 val_mcc=0.6843 best_t=0.32 time=3.27s\n",
      "Epoch 14/50 loss=0.1021 val_loss=0.1085 val_mcc=0.6860 best_t=0.11 time=3.26s\n",
      "Epoch 15/50 loss=0.1065 val_loss=0.1096 val_mcc=0.6860 best_t=0.43 time=3.27s\n",
      "Epoch 16/50 loss=0.1051 val_loss=0.1090 val_mcc=0.7211 best_t=0.59 time=3.24s\n",
      "Save Model on epoch 16\n",
      "Epoch 17/50 loss=0.1163 val_loss=0.1075 val_mcc=0.7027 best_t=0.14 time=3.28s\n",
      "Epoch 18/50 loss=0.0987 val_loss=0.1014 val_mcc=0.6843 best_t=0.25 time=3.27s\n",
      "Epoch 19/50 loss=0.0955 val_loss=0.1024 val_mcc=0.7204 best_t=0.37 time=3.28s\n",
      "Epoch 20/50 loss=0.0995 val_loss=0.1152 val_mcc=0.6883 best_t=0.10 time=3.28s\n",
      "Epoch 21/50 loss=0.1089 val_loss=0.1091 val_mcc=0.6759 best_t=0.14 time=3.27s\n",
      "Epoch 22/50 loss=0.0959 val_loss=0.1083 val_mcc=0.7027 best_t=0.10 time=3.29s\n",
      "Epoch 23/50 loss=0.1039 val_loss=0.0957 val_mcc=0.6931 best_t=0.34 time=3.25s\n",
      "Epoch 24/50 loss=0.0964 val_loss=0.0965 val_mcc=0.6860 best_t=0.32 time=3.28s\n",
      "Epoch 25/50 loss=0.0915 val_loss=0.0953 val_mcc=0.7061 best_t=0.10 time=3.26s\n",
      "Epoch 26/50 loss=0.1132 val_loss=0.1258 val_mcc=0.7123 best_t=0.58 time=3.29s\n",
      "Epoch 27/50 loss=0.1203 val_loss=0.0932 val_mcc=0.7207 best_t=0.12 time=3.28s\n",
      "Epoch 28/50 loss=0.1024 val_loss=0.1024 val_mcc=0.6759 best_t=0.26 time=3.28s\n",
      "Epoch 29/50 loss=0.1022 val_loss=0.0931 val_mcc=0.6883 best_t=0.28 time=3.26s\n",
      "Epoch 30/50 loss=0.0982 val_loss=0.0950 val_mcc=0.6808 best_t=0.25 time=3.26s\n",
      "Epoch 31/50 loss=0.0948 val_loss=0.0901 val_mcc=0.6942 best_t=0.20 time=3.28s\n",
      "Epoch 32/50 loss=0.1062 val_loss=0.0920 val_mcc=0.7061 best_t=0.20 time=3.26s\n",
      "Epoch 33/50 loss=0.0946 val_loss=0.1012 val_mcc=0.7041 best_t=0.56 time=3.27s\n",
      "Epoch 34/50 loss=0.0941 val_loss=0.0895 val_mcc=0.7311 best_t=0.38 time=3.28s\n",
      "Save Model on epoch 34\n",
      "Epoch 35/50 loss=0.1081 val_loss=0.1099 val_mcc=0.7041 best_t=0.07 time=3.26s\n",
      "Epoch 36/50 loss=0.0999 val_loss=0.0978 val_mcc=0.7297 best_t=0.17 time=3.26s\n",
      "Epoch 37/50 loss=0.0908 val_loss=0.0931 val_mcc=0.7123 best_t=0.16 time=3.24s\n",
      "Epoch 38/50 loss=0.0938 val_loss=0.0967 val_mcc=0.7219 best_t=0.31 time=3.28s\n",
      "Epoch 39/50 loss=0.0963 val_loss=0.0868 val_mcc=0.7295 best_t=0.36 time=3.26s\n",
      "Epoch 40/50 loss=0.0968 val_loss=0.1117 val_mcc=0.7041 best_t=0.06 time=3.29s\n",
      "Epoch 41/50 loss=0.0842 val_loss=0.1076 val_mcc=0.7219 best_t=0.08 time=3.28s\n",
      "Epoch 42/50 loss=0.0783 val_loss=0.0921 val_mcc=0.7123 best_t=0.21 time=3.28s\n",
      "Epoch 43/50 loss=0.0817 val_loss=0.1252 val_mcc=0.6448 best_t=0.06 time=3.27s\n",
      "Epoch 44/50 loss=0.0696 val_loss=0.1252 val_mcc=0.6457 best_t=0.20 time=3.26s\n",
      "Epoch 45/50 loss=0.0639 val_loss=0.1212 val_mcc=0.6567 best_t=0.22 time=3.28s\n",
      "Epoch 46/50 loss=0.0740 val_loss=0.1134 val_mcc=0.6250 best_t=0.42 time=3.28s\n",
      "Epoch 47/50 loss=0.0551 val_loss=0.1223 val_mcc=0.6059 best_t=0.19 time=3.28s\n",
      "Epoch 48/50 loss=0.0547 val_loss=0.1413 val_mcc=0.5227 best_t=0.80 time=3.29s\n",
      "Epoch 49/50 loss=0.0565 val_loss=0.1218 val_mcc=0.5882 best_t=0.10 time=3.29s\n",
      "Epoch 50/50 loss=0.0384 val_loss=0.1049 val_mcc=0.6727 best_t=0.57 time=3.26s\n",
      "Validation loss:  0.08949925750494003\n",
      "Fold 5\n",
      "Epoch 1/50 loss=0.2934 val_loss=0.1712 val_mcc=0.4149 best_t=0.11 time=3.27s\n",
      "Save Model on epoch 1\n",
      "Epoch 2/50 loss=0.2145 val_loss=0.1631 val_mcc=0.4210 best_t=0.24 time=3.26s\n",
      "Save Model on epoch 2\n",
      "Epoch 3/50 loss=0.2230 val_loss=0.1782 val_mcc=0.3834 best_t=0.14 time=3.26s\n",
      "Epoch 4/50 loss=0.2123 val_loss=0.1631 val_mcc=0.4425 best_t=0.41 time=3.26s\n",
      "Save Model on epoch 4\n",
      "Epoch 5/50 loss=0.1754 val_loss=0.1347 val_mcc=0.4557 best_t=0.31 time=3.26s\n",
      "Save Model on epoch 5\n",
      "Epoch 6/50 loss=0.1761 val_loss=0.1855 val_mcc=0.6468 best_t=0.59 time=3.29s\n",
      "Save Model on epoch 6\n",
      "Epoch 7/50 loss=0.1672 val_loss=0.1200 val_mcc=0.5421 best_t=0.39 time=3.28s\n",
      "Epoch 8/50 loss=0.1208 val_loss=0.0976 val_mcc=0.6556 best_t=0.24 time=3.27s\n",
      "Save Model on epoch 8\n",
      "Epoch 9/50 loss=0.1053 val_loss=0.1011 val_mcc=0.6556 best_t=0.13 time=3.26s\n",
      "Epoch 10/50 loss=0.1064 val_loss=0.1037 val_mcc=0.6594 best_t=0.15 time=3.28s\n",
      "Save Model on epoch 10\n",
      "Epoch 11/50 loss=0.0980 val_loss=0.1047 val_mcc=0.6483 best_t=0.03 time=3.27s\n",
      "Epoch 12/50 loss=0.1075 val_loss=0.0981 val_mcc=0.6414 best_t=0.09 time=3.26s\n",
      "Epoch 13/50 loss=0.0994 val_loss=0.1027 val_mcc=0.6663 best_t=0.06 time=3.30s\n",
      "Save Model on epoch 13\n",
      "Epoch 14/50 loss=0.1037 val_loss=0.1070 val_mcc=0.6594 best_t=0.19 time=3.28s\n",
      "Epoch 15/50 loss=0.1125 val_loss=0.1082 val_mcc=0.6592 best_t=0.41 time=3.30s\n",
      "Epoch 16/50 loss=0.1045 val_loss=0.1030 val_mcc=0.6523 best_t=0.29 time=3.26s\n",
      "Epoch 17/50 loss=0.1104 val_loss=0.1071 val_mcc=0.6555 best_t=0.03 time=3.27s\n",
      "Epoch 18/50 loss=0.0983 val_loss=0.1158 val_mcc=0.6468 best_t=0.24 time=3.26s\n",
      "Epoch 19/50 loss=0.0937 val_loss=0.1045 val_mcc=0.6597 best_t=0.17 time=3.25s\n",
      "Epoch 20/50 loss=0.0899 val_loss=0.1072 val_mcc=0.6523 best_t=0.52 time=3.29s\n",
      "Epoch 21/50 loss=0.0931 val_loss=0.1090 val_mcc=0.6727 best_t=0.18 time=3.27s\n",
      "Save Model on epoch 21\n",
      "Epoch 22/50 loss=0.1044 val_loss=0.0980 val_mcc=0.6646 best_t=0.29 time=3.29s\n",
      "Epoch 23/50 loss=0.1024 val_loss=0.1020 val_mcc=0.6835 best_t=0.25 time=3.28s\n",
      "Save Model on epoch 23\n",
      "Epoch 24/50 loss=0.0940 val_loss=0.1113 val_mcc=0.6657 best_t=0.18 time=3.28s\n",
      "Epoch 25/50 loss=0.1143 val_loss=0.1088 val_mcc=0.6561 best_t=0.17 time=3.26s\n",
      "Epoch 26/50 loss=0.1050 val_loss=0.1021 val_mcc=0.7025 best_t=0.31 time=3.26s\n",
      "Save Model on epoch 26\n",
      "Epoch 27/50 loss=0.0985 val_loss=0.1107 val_mcc=0.6928 best_t=0.35 time=3.28s\n",
      "Epoch 28/50 loss=0.1011 val_loss=0.0982 val_mcc=0.6745 best_t=0.24 time=3.28s\n",
      "Epoch 29/50 loss=0.0978 val_loss=0.1023 val_mcc=0.6745 best_t=0.19 time=3.27s\n",
      "Epoch 30/50 loss=0.1011 val_loss=0.0988 val_mcc=0.6657 best_t=0.44 time=3.27s\n",
      "Epoch 31/50 loss=0.0888 val_loss=0.1044 val_mcc=0.6567 best_t=0.33 time=3.29s\n",
      "Epoch 32/50 loss=0.0891 val_loss=0.1042 val_mcc=0.6657 best_t=0.16 time=3.28s\n",
      "Epoch 33/50 loss=0.0905 val_loss=0.1031 val_mcc=0.6745 best_t=0.20 time=3.26s\n",
      "Epoch 34/50 loss=0.0876 val_loss=0.0979 val_mcc=0.6468 best_t=0.11 time=3.29s\n",
      "Epoch 35/50 loss=0.0900 val_loss=0.1053 val_mcc=0.6799 best_t=0.41 time=3.29s\n",
      "Epoch 36/50 loss=0.0877 val_loss=0.1030 val_mcc=0.6657 best_t=0.19 time=3.25s\n",
      "Epoch 37/50 loss=0.0951 val_loss=0.1064 val_mcc=0.6799 best_t=0.46 time=3.26s\n",
      "Epoch 38/50 loss=0.0958 val_loss=0.1029 val_mcc=0.6449 best_t=0.34 time=3.25s\n",
      "Epoch 39/50 loss=0.0864 val_loss=0.1059 val_mcc=0.6556 best_t=0.17 time=3.27s\n",
      "Epoch 40/50 loss=0.0810 val_loss=0.1094 val_mcc=0.6739 best_t=0.09 time=3.26s\n",
      "Epoch 41/50 loss=0.0779 val_loss=0.1039 val_mcc=0.6468 best_t=0.12 time=3.28s\n",
      "Epoch 42/50 loss=0.0734 val_loss=0.1293 val_mcc=0.6454 best_t=0.13 time=3.28s\n",
      "Epoch 43/50 loss=0.0635 val_loss=0.1321 val_mcc=0.5633 best_t=0.05 time=3.27s\n",
      "Epoch 44/50 loss=0.0672 val_loss=0.1287 val_mcc=0.5761 best_t=0.38 time=3.28s\n",
      "Epoch 45/50 loss=0.0626 val_loss=0.1331 val_mcc=0.6148 best_t=0.10 time=3.25s\n",
      "Epoch 46/50 loss=0.0619 val_loss=0.1288 val_mcc=0.6556 best_t=0.13 time=3.29s\n",
      "Epoch 47/50 loss=0.0515 val_loss=0.1575 val_mcc=0.6937 best_t=0.24 time=3.27s\n",
      "Epoch 48/50 loss=0.0380 val_loss=0.1601 val_mcc=0.6765 best_t=0.13 time=3.29s\n",
      "Epoch 49/50 loss=0.0312 val_loss=0.2323 val_mcc=0.5639 best_t=0.15 time=3.28s\n",
      "Epoch 50/50 loss=0.0277 val_loss=0.1892 val_mcc=0.6646 best_t=0.03 time=3.29s\n",
      "Validation loss:  0.10205872356891632\n"
     ]
    }
   ],
   "source": [
    "fold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019)\n",
    "train_preds = np.zeros((X.shape[0],))\n",
    "\n",
    "for i, (trn_index, val_index) in enumerate(fold.split(X, y)):\n",
    "    X_train = torch.tensor(X[trn_index], dtype=torch.float32).cuda()\n",
    "    X_val = torch.tensor(X[val_index], dtype=torch.float32).cuda()\n",
    "    y_train = torch.tensor(y[trn_index, np.newaxis], dtype=torch.float32).cuda()\n",
    "    y_val = torch.tensor(y[val_index, np.newaxis], dtype=torch.float32).cuda()\n",
    "    \n",
    "    print(f\"Fold {i + 1}\")\n",
    "    model = LSTMNet(256, 512, X.shape, 30)\n",
    "    model.cuda()\n",
    "    \n",
    "    valid_preds = train_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        f\"best{i}.pt\",\n",
    "        anneal=False,\n",
    "        epochs=50,\n",
    "        seed=1029)\n",
    "    \n",
    "    train_preds[val_index] = valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "d706c7c100242bccd4349bee01d52df59a0ea864"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC:  0.6953482545840397\n",
      "threshold:  0.31\n"
     ]
    }
   ],
   "source": [
    "search_result = threshold_search(y, train_preds)\n",
    "print(\"MCC: \", search_result[\"mcc\"])\n",
    "print(\"threshold: \", search_result[\"threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "54e33378a6dbd3acb26de881f98221ba9fafd674"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_measurement</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>2904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>2904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>2905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_measurement  phase\n",
       "signal_id                       \n",
       "8712                 2904      0\n",
       "8713                 2904      1\n",
       "8714                 2904      2\n",
       "8715                 2905      0\n",
       "8716                 2905      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test = pd.read_csv('../input/metadata_test.csv')\n",
    "meta_test = meta_test.set_index(['signal_id'])\n",
    "meta_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "e1f84ac678c19311c41a7cbb30803f5c17df4f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8712 30 20337 677 27 20337\n",
      "[[8712, 9389], [9389, 10066], [10066, 10743], [10743, 11420], [11420, 12097], [12097, 12774], [12774, 13451], [13451, 14128], [14128, 14805], [14805, 15482], [15482, 16159], [16159, 16836], [16836, 17513], [17513, 18190], [18190, 18867], [18867, 19544], [19544, 20221], [20221, 20898], [20898, 21575], [21575, 22252], [22252, 22929], [22929, 23606], [23606, 24283], [24283, 24960], [24960, 25637], [25637, 26314], [26314, 26991], [26991, 27668], [27668, 28345], [28345, 29022], [29022, 29049]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 677/677 [01:05<00:00, 10.47it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.29it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.45it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.31it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.35it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.33it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.33it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.24it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.27it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.34it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.45it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.27it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.44it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.44it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.25it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.29it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.29it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.27it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.23it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.24it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00,  9.93it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.22it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00,  9.57it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.37it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.40it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.35it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.36it/s]\n",
      "100%|██████████| 677/677 [01:06<00:00, 10.25it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.25it/s]\n",
      "100%|██████████| 677/677 [01:05<00:00, 10.29it/s]\n",
      "100%|██████████| 27/27 [00:02<00:00, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 37s, sys: 29.8 s, total: 36min 6s\n",
      "Wall time: 35min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# First we daclarete a series of parameters to initiate the loading of the main data\n",
    "# it is too large, it is impossible to load in one time, so we are doing it in dividing in 10 parts\n",
    "first_sig = meta_test.index[0]\n",
    "n_parts = 30\n",
    "max_line = len(meta_test)\n",
    "part_size = int(max_line / n_parts)\n",
    "last_part = max_line % n_parts\n",
    "print(first_sig, n_parts, max_line, part_size, last_part, n_parts * part_size + last_part)\n",
    "# Here we create a list of lists with start index and end index for each of the 10 parts and one for the last partial part\n",
    "start_end = [[x, x+part_size] for x in range(first_sig, max_line + first_sig, part_size)]\n",
    "start_end = start_end[:-1] + [[start_end[-1][0], start_end[-1][0] + last_part]]\n",
    "print(start_end)\n",
    "X_test = []\n",
    "# now, very like we did above with the train data, we convert the test data part by part\n",
    "# transforming the 3 phases 800000 measurement in matrix (160,57)\n",
    "for start, end in start_end:\n",
    "    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(i) for i in range(start, end)]).to_pandas()\n",
    "    for i in tqdm(subset_test.columns):\n",
    "        id_measurement, phase = meta_test.loc[int(i)]\n",
    "        subset_test_col = subset_test[i]\n",
    "        subset_trans = transform_ts(subset_test_col, n_dim=n_dim)\n",
    "        X_test.append([i, id_measurement, phase, subset_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "4eff9a53e182c3b499b1903936c9517702454fd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6779, 160, 57)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_input = np.asarray([np.concatenate([X_test[i][3],X_test[i+1][3], X_test[i+2][3]], axis=1) for i in range(0,len(X_test), 3)])\n",
    "np.save(\"X_test.npy\",X_test_input)\n",
    "X_test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "d2047a820c543d474fe3bfa611c012f3cd3d7bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "print(len(submission))\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "9e2d89485aa3d4bd6b66881e158d965a7382805a"
   },
   "outputs": [],
   "source": [
    "test_batch_size = 300\n",
    "\n",
    "X_test = torch.tensor(X_test_input, dtype=torch.float32).cuda()\n",
    "test = torch.utils.data.TensorDataset(X_test)\n",
    "test_loader = torch.utils.data.DataLoader(test, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "fd2364263d3f4f617fd11767a456187f29ad46d8"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'n_attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e8bb054a224c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_SPLITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"best{i}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'n_attention'"
     ]
    }
   ],
   "source": [
    "preds_test = []\n",
    "for i in range(N_SPLITS):\n",
    "    y_pred = np.zeros(X_test.size(0))\n",
    "    model = LSTMNet(128, 64, X_test.shape)\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(f\"best{i}.pt\"))\n",
    "    model.eval()\n",
    "    \n",
    "    for j, (x_batch,) in enumerate(test_loader):\n",
    "        y_p = model(x_batch).detach()\n",
    "        y_pred[j * test_batch_size:(j+1) * test_batch_size] = sigmoid(y_p.cpu().numpy())[:, 0]\n",
    "    pred_3 = []\n",
    "    for pred_scalar in y_pred:\n",
    "        for i in range(3):\n",
    "            pred_3.append(pred_scalar)\n",
    "    preds_test.append(pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "115554aa4cce2cae576961f22952c4fb431310e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = (np.squeeze(np.mean(preds_test, axis=0)) > search_result[\"threshold\"]).astype(np.int)\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "69266628f7ca6e1e7a9e9d60539bda4b73edcc02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id  target\n",
       "0       8712       0\n",
       "1       8713       0\n",
       "2       8714       0\n",
       "3       8715       0\n",
       "4       8716       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"target\"] = preds_test\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "8e7df539125f6092abd6c16938555faffd8f89b7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
